#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
@Author  : Zijun Deng
@Date    : 2/17/2026
@File    : sm_searcher.py
@Description: Smart Money Searcher V7 - çƒ­é—¨å¸çŒæ‰‹æŒ–æ˜
              1. çƒ­é—¨å¸ç­›é€‰: DexScreener è¿‡å»24å°æ—¶æ¶¨å¹… > 1000%
              2. ä»£å¸å¹´é¾„: æ”¾å®½è‡³ 12 å°æ—¶å†…
              3. å›æº¯: æœ€å¤š 20 é¡µ
              4. åˆç­›ä¹°å®¶: å¼€ç›˜ 15 ç§’åä¹°å…¥ï¼Œä¸”åœ¨è¯¥ä»£å¸è‡³å°‘èµšå– 200%ï¼ˆå·²æ¸…ä»“æˆ–æœªæ¸…ä»“ï¼‰
              5. ç­›é€‰åçš„é’±åŒ…åšè¯„åˆ†å…¥åº“
"""

import asyncio
import json
import logging
import os
import time
from collections import defaultdict
from typing import Dict, Tuple, Set

import httpx

from config.settings import (
    helius_key_pool,
    MIN_TOKEN_AGE_SEC,
    MAX_TOKEN_AGE_SEC,
    MAX_BACKTRACK_PAGES,
    RECENT_TX_COUNT_FOR_FREQUENCY,
    MIN_AVG_TX_INTERVAL_SEC,
    MIN_NATIVE_LAMPORTS_FOR_REAL,
    SCANNED_HISTORY_FILE,
    SM_MIN_DELAY_SEC,
    SM_MAX_DELAY_SEC,
    SM_AUDIT_TX_LIMIT,
    SM_MIN_BUY_SOL,
    SM_MAX_BUY_SOL,
    SM_MIN_TOKEN_PROFIT_PCT,
    SM_MIN_WIN_RATE,
    SM_MIN_TOTAL_PROFIT,
    SM_MIN_HUNTER_SCORE,
)
from utils.logger import get_logger

logger = get_logger(__name__)
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("httpcore").setLevel(logging.WARNING)

# ä¸ SmartFlow3 ä¸€è‡´ï¼šåªæŠŠã€ŒçœŸå®ä¹°å–ã€ç®—ä½œäº¤æ˜“ï¼Œå¿½ç•¥ SOL/USDC/USDT ç­‰
IGNORE_MINTS = {
    "So11111111111111111111111111111111111111112",  # WSOL
    "EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v",  # USDC
    "Es9vMFrzaCERmJfrF4H2FYD4KCoNkY11McCe8BenwNYB",   # USDT
}
MIN_NATIVE_LAMPORTS_FOR_REAL = int(0.01 * 1e9)  # è‡³å°‘ 0.01 SOL çš„ native è½¬è´¦æ‰ç®—ã€ŒçœŸå®ã€


def tx_has_real_trade(tx: dict) -> bool:
    """
    åˆ¤æ–­è¯¥ç¬”é“¾ä¸Šäº¤æ˜“æ˜¯å¦åŒ…å«ã€ŒçœŸå®äº¤æ˜“ã€ï¼šéçº¯æˆæƒ/å¤±è´¥/ç²‰å°˜ã€‚
    ä¸ SmartFlow3 ä¸€è‡´ï¼šå­˜åœ¨é IGNORE ä»£å¸çš„ tokenTransferï¼Œæˆ– meaningful çš„ nativeTransferã€‚
    """
    for tt in tx.get("tokenTransfers", []):
        if tt.get("mint") and tt["mint"] not in IGNORE_MINTS:
            return True
    for nt in tx.get("nativeTransfers", []):
        if (nt.get("amount") or 0) >= MIN_NATIVE_LAMPORTS_FOR_REAL:
            return True
    return False


def is_real_trade_for_address(tx: dict, address: str) -> bool:
    """
    åˆ¤æ–­è¯¥ç¬”äº¤æ˜“å¯¹ç»™å®šåœ°å€è€Œè¨€æ˜¯å¦ä¸ºã€ŒçœŸå®äº¤æ˜“ã€ï¼šè¯¥åœ°å€å‚ä¸äº†é IGNORE çš„ token æˆ– meaningful çš„ nativeã€‚
    """
    for tt in tx.get("tokenTransfers", []):
        if tt.get("mint") in IGNORE_MINTS:
            continue
        if tt.get("fromUserAccount") == address or tt.get("toUserAccount") == address:
            return True
    for nt in tx.get("nativeTransfers", []):
        if (nt.get("amount") or 0) < MIN_NATIVE_LAMPORTS_FOR_REAL:
            continue
        if nt.get("fromUserAccount") == address or nt.get("toUserAccount") == address:
            return True
    return False


def _is_frequent_trader_by_real_txs(txs: list, address: str) -> bool:
    """
    æ ¹æ®ã€ŒçœŸå®äº¤æ˜“ã€æ—¶é—´æˆ³è®¡ç®—å¹³å‡é—´éš”ï¼›åªç»Ÿè®¡è¯¥åœ°å€å‚ä¸çš„çœŸå®ä¹°å–ã€‚
    txs: å·²è§£æçš„äº¤æ˜“åˆ—è¡¨ï¼ˆä¸ sigs é¡ºåºä¸€è‡´ï¼Œæ–°åœ¨å‰ï¼‰ï¼Œæ¥è‡ª fetch_parsed_transactionsã€‚
    """
    real_ts = []
    for tx in txs:
        if len(real_ts) >= RECENT_TX_COUNT_FOR_FREQUENCY:
            break
        if not is_real_trade_for_address(tx, address):
            continue
        ts = tx.get("timestamp")
        if ts is not None:
            real_ts.append(ts)
    if len(real_ts) < 2:
        return False
    real_ts.sort()
    span = real_ts[-1] - real_ts[0]
    avg_interval = span / (len(real_ts) - 1)
    return avg_interval < MIN_AVG_TX_INTERVAL_SEC


def _normalize_token_amount(raw) -> float:
    """å°† Helius tokenAmount è½¬ä¸ºæµ®ç‚¹æ•°ã€‚æ”¯æŒæ•°å­—æˆ–å¯¹è±¡ { amount: string, decimals: int }ï¼ˆä¸ SmartFlow3 ä¸€è‡´ï¼‰ã€‚"""
    if raw is None:
        return 0.0
    if isinstance(raw, (int, float)):
        return float(raw)
    if isinstance(raw, dict):
        amount = float(raw.get("amount") or 0)
        decimals = int(raw.get("decimals") or 0)
        return amount / (10 ** decimals) if decimals else amount
    return float(raw)


class TransactionParser:
    def __init__(self, target_wallet: str):
        self.target_wallet = target_wallet
        self.wsol_mint = "So11111111111111111111111111111111111111112"

    def parse_transaction(self, tx: dict) -> Tuple[float, Dict[str, float], int]:
        timestamp = tx.get('timestamp', 0)
        native_sol_change = 0.0
        wsol_change = 0.0
        token_changes = defaultdict(float)

        for nt in tx.get('nativeTransfers', []):
            if nt.get('fromUserAccount') == self.target_wallet:
                native_sol_change -= nt.get('amount', 0) / 1e9
            if nt.get('toUserAccount') == self.target_wallet:
                native_sol_change += nt.get('amount', 0) / 1e9

        for tt in tx.get('tokenTransfers', []):
            mint = tt.get('mint', '')
            amt = _normalize_token_amount(tt.get('tokenAmount'))
            if mint == self.wsol_mint:
                if tt.get('fromUserAccount') == self.target_wallet:
                    wsol_change -= amt
                if tt.get('toUserAccount') == self.target_wallet:
                    wsol_change += amt
            else:
                if tt.get('fromUserAccount') == self.target_wallet:
                    token_changes[mint] -= amt
                if tt.get('toUserAccount') == self.target_wallet:
                    token_changes[mint] += amt

        sol_change = 0.0
        if abs(native_sol_change) < 1e-9:
            sol_change = wsol_change
        elif abs(wsol_change) < 1e-9:
            sol_change = native_sol_change
        elif native_sol_change * wsol_change > 0:
            sol_change = native_sol_change if abs(native_sol_change) > abs(wsol_change) else wsol_change
        else:
            sol_change = native_sol_change + wsol_change

        return sol_change, dict(token_changes), timestamp


class TokenAttributionCalculator:
    @staticmethod
    def calculate_attribution(sol_change: float, token_changes: Dict[str, float]):
        buy_attrs, sell_attrs = {}, {}
        if abs(sol_change) < 1e-9: return buy_attrs, sell_attrs
        buys = {m: a for m, a in token_changes.items() if a > 0}
        sells = {m: abs(a) for m, a in token_changes.items() if a < 0}

        if sol_change < 0:
            total = sum(buys.values())
            if total > 0:
                cost_per = abs(sol_change) / total
                for m, a in buys.items(): buy_attrs[m] = cost_per * a
        elif sol_change > 0:
            total = sum(sells.values())
            if total > 0:
                gain_per = sol_change / total
                for m, a in sells.items(): sell_attrs[m] = gain_per * a
        return buy_attrs, sell_attrs


class SmartMoneySearcher:
    def __init__(self):
        self._pool = helius_key_pool
        self._update_urls()

    def _update_urls(self):
        """ä» Key æ± æ›´æ–°å½“å‰ RPC / API URLã€‚"""
        self.api_key = self._pool.get_api_key()
        self.rpc_url = self._pool.get_rpc_url()
        self.base_api_url = "https://api.helius.xyz/v0"

        # åˆç­›å‚æ•° (æ¥è‡ª config/settings.py)
        self.min_delay_sec = SM_MIN_DELAY_SEC
        self.max_delay_sec = SM_MAX_DELAY_SEC
        self.audit_tx_limit = SM_AUDIT_TX_LIMIT

        self.scanned_tokens: Set[str] = set()
        self._load_scanned_history()

    def _ensure_data_dir(self):
        if not os.path.exists("data"):
            os.makedirs("data")

    def _load_scanned_history(self):
        self._ensure_data_dir()
        if os.path.exists(SCANNED_HISTORY_FILE):
            try:
                with open(SCANNED_HISTORY_FILE, 'r') as f:
                    self.scanned_tokens = set(json.load(f))
                logger.info(f"ğŸ“‚ å·²åŠ è½½ {len(self.scanned_tokens)} ä¸ªå†å²æ‰«æä»£å¸è®°å½•")
            except Exception:
                logger.exception("âš ï¸ åŠ è½½æ‰«æå†å²å¤±è´¥")

    def _save_scanned_token(self, token_address: str):
        if token_address in self.scanned_tokens: return
        self.scanned_tokens.add(token_address)
        try:
            with open(SCANNED_HISTORY_FILE, 'w') as f:
                json.dump(list(self.scanned_tokens), f)
        except Exception:
            logger.exception("ä¿å­˜æ‰«æå†å²å¤±è´¥")

    async def _rpc_post(self, client, method, params):
        payload = {"jsonrpc": "2.0", "id": 1, "method": method, "params": params}

        # === [æ–°å¢] é‡è¯•æœºåˆ¶ (æœ€å¤šè¯• 3 æ¬¡) ===
        max_retries = 3
        base_delay = 1.0

        for attempt in range(max_retries):
            try:
                # [ä¼˜åŒ–] å¢åŠ  timeout åˆ° 30ç§’ï¼Œé˜²æ­¢æ·±ç¿»é¡µæ—¶è¶…æ—¶
                resp = await client.post(self.rpc_url, json=payload, timeout=30.0)

                if resp.status_code == 200:
                    data = resp.json()
                    if "result" in data:
                        return data["result"]
                    elif "error" in data:
                        # å¦‚æœæ˜¯é™æµé”™è¯¯ (429)ï¼Œè®°å½•å¹¶é‡è¯•
                        err_msg = data.get("error", {}).get("message", "")
                        if "Rate limit" in err_msg or "429" in str(resp.status_code):
                            logger.warning("âš ï¸ RPC é™æµ (å°è¯• %s/%s)ï¼Œåˆ‡æ¢ Key: %s", attempt + 1, max_retries, err_msg)
                            self._pool.mark_current_failed()
                            self._update_urls()
                        else:
                            # å…¶ä»–ä¸šåŠ¡é”™è¯¯ç›´æ¥è¿”å› None
                            # logger.warning(f"RPC ä¸šåŠ¡é”™è¯¯: {err_msg}")
                            return None
                elif resp.status_code == 429:
                    logger.warning("âš ï¸ RPC HTTP 429 é™æµ (å°è¯• %s/%s)ï¼Œåˆ‡æ¢ Key", attempt + 1, max_retries)
                    self._pool.mark_current_failed()
                    self._update_urls()
                else:
                    logger.warning(f"RPC è¯·æ±‚å¤±è´¥: {resp.status_code}")

            except (httpx.TimeoutException, httpx.NetworkError) as e:
                logger.warning("âš ï¸ RPC ç½‘ç»œæ³¢åŠ¨ (å°è¯• %s/%s): %s", attempt + 1, max_retries, e)
            except Exception:
                logger.exception("âŒ RPC æœªçŸ¥é”™è¯¯")
                return None

            # æŒ‡æ•°é€€é¿ï¼šæ¯æ¬¡å¤±è´¥å¤šç¡ä¸€ä¼šå„¿ (1s -> 2s -> 4s)
            if attempt < max_retries - 1:
                sleep_time = base_delay * (2 ** attempt)
                await asyncio.sleep(sleep_time)

        logger.error(f"âŒ RPC {method} æœ€ç»ˆå¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡")
        return None

    async def get_signatures(self, client, address, limit=100, before=None):
        params = [address, {"limit": limit}]
        if before:
            params[1]["before"] = before
        return await self._rpc_post(client, "getSignaturesForAddress", params)

    async def is_frequent_trader(self, client, address: str) -> bool:
        """
        åˆ¤æ–­è¯¥åœ°å€æ˜¯å¦ä¸ºã€Œé¢‘ç¹äº¤æ˜“ã€ï¼šæœ€è¿‘ 100 ç¬”ã€ŒçœŸå®äº¤æ˜“ã€å¹³å‡é—´éš” < 5 åˆ†é’Ÿã€‚
        åªç»Ÿè®¡è¯¥åœ°å€å‚ä¸çš„çœŸå®ä¹°å–ï¼ˆé IGNORE ä»£å¸ / meaningful nativeï¼‰ï¼Œä¸ SmartFlow3 ä¸€è‡´ã€‚
        """
        sigs = await self.get_signatures(client, address, limit=RECENT_TX_COUNT_FOR_FREQUENCY)
        if not sigs:
            return False
        txs = await self.fetch_parsed_transactions(client, sigs)
        return _is_frequent_trader_by_real_txs(txs or [], address)

    async def fetch_parsed_transactions(self, client, signatures):
        if not signatures: return []
        chunk_size = 90
        all_txs = []
        for i in range(0, len(signatures), chunk_size):
            batch = signatures[i:i + chunk_size]
            payload = {"transactions": [s['signature'] for s in batch]}
            url = f"{self.base_api_url}/transactions?api-key={self.api_key}"
            try:
                resp = await client.post(url, json=payload, timeout=30.0)
                if resp.status_code == 200:
                    all_txs.extend(resp.json())
                elif resp.status_code == 429 and self._pool.size > 1:
                    self._pool.mark_current_failed()
                    self._update_urls()
            except Exception:
                logger.exception("fetch_parsed_transactions æ‰¹é‡è¯·æ±‚å¼‚å¸¸")
        return all_txs

    async def analyze_hunter_performance(self, client, hunter_address, exclude_token=None):
        sigs = await self.get_signatures(client, hunter_address, limit=self.audit_tx_limit)
        if not sigs:
            return None
        txs = await self.fetch_parsed_transactions(client, sigs)
        if not txs:
            return None
        # é¢‘ç¹äº¤æ˜“è¿‡æ»¤ï¼šåªç»Ÿè®¡ã€ŒçœŸå®äº¤æ˜“ã€ï¼Œæœ€è¿‘ 100 ç¬”çœŸå®ä¹°å–å¹³å‡é—´éš” < 5 åˆ†é’Ÿåˆ™å‰”é™¤
        if _is_frequent_trader_by_real_txs(txs, hunter_address):
            logger.info("â­ï¸ å‰”é™¤é¢‘ç¹äº¤æ˜“åœ°å€ %s.. (çœŸå®äº¤æ˜“å¹³å‡é—´éš”<5åˆ†é’Ÿ)", hunter_address)
            return None
        if not txs: return None

        parser = TransactionParser(hunter_address)
        calc = TokenAttributionCalculator()
        projects = defaultdict(lambda: {"buy_sol": 0.0, "sell_sol": 0.0, "tokens": 0.0})

        txs.sort(key=lambda x: x.get('timestamp', 0))
        for tx in txs:
            try:
                sol_change, token_changes, _ = parser.parse_transaction(tx)
                if not token_changes: continue
                buy_attrs, sell_attrs = calc.calculate_attribution(sol_change, token_changes)
                for mint, delta in token_changes.items():
                    if exclude_token and mint == exclude_token: continue
                    if abs(delta) < 1e-9: continue
                    projects[mint]["tokens"] += delta
                    if mint in buy_attrs: projects[mint]["buy_sol"] += buy_attrs[mint]
                    if mint in sell_attrs: projects[mint]["sell_sol"] += sell_attrs[mint]
            except Exception:
                logger.debug("è§£æå•ç¬”äº¤æ˜“è·³è¿‡", exc_info=True)
                continue

        valid_projects = []
        for mint, data in projects.items():
            if data["buy_sol"] > 0.05:
                net_profit = data["sell_sol"] - data["buy_sol"]
                roi = (net_profit / data["buy_sol"]) * 100
                valid_projects.append({"profit": net_profit, "roi": roi, "cost": data["buy_sol"]})

        if not valid_projects: return None

        recent = valid_projects[-15:]
        total_profit = sum(p["profit"] for p in recent)
        wins = [p for p in recent if p["profit"] > 0]
        win_rate = len(wins) / len(recent)
        worst_roi = max(-100, min([p["roi"] for p in recent])) if recent else 0

        return {"win_rate": win_rate, "worst_roi": worst_roi, "total_profit": total_profit, "count": len(recent)}

    async def _get_token_price_sol(self, client, token_address: str) -> float | None:
        """
        ä» DexScreener è·å–ä»£å¸å½“å‰ä»·æ ¼ (1 token = ? SOL)ï¼Œç”¨äºè®¡ç®—æœªå®ç°æ”¶ç›Šã€‚
        """
        url = f"https://api.dexscreener.com/latest/dex/tokens/{token_address}"
        try:
            resp = await client.get(url, timeout=5.0)
            if resp.status_code != 200:
                return None
            data = resp.json()
            pairs = data.get("pairs", [])
            wsol = "So11111111111111111111111111111111111111112"
            for p in pairs:
                if p.get("chainId") != "solana":
                    continue
                base = p.get("baseToken") or {}
                quote = p.get("quoteToken") or {}
                base_addr = (base.get("address") or "").strip()
                quote_addr = (quote.get("address") or "").strip()
                price_native = p.get("priceNative")
                if price_native is None:
                    continue
                try:
                    pr = float(price_native)
                except (TypeError, ValueError):
                    continue
                if pr <= 0:
                    continue
                is_sol = lambda a: a == wsol or "11111111111111111111" in (a or "")
                if base_addr == token_address and is_sol(quote_addr):
                    return pr
                if quote_addr == token_address and is_sol(base_addr):
                    return 1.0 / pr if pr > 0 else None
        except Exception:
            logger.debug("è·å–ä»£å¸ä»·æ ¼å¤±è´¥", exc_info=True)
        return None

    async def get_hunter_profit_on_token(self, client, hunter_address: str, token_address: str) -> float | None:
        """
        è®¡ç®—çŒæ‰‹åœ¨è¯¥ä»£å¸ä¸Šçš„æ”¶ç›Šç‡ (ROI %)ï¼Œå·²æ¸…ä»“ç”¨å–å‡ºæ”¶ç›Šç®—ï¼Œæœªæ¸…ä»“ç”¨ç°ä»·ä¼°ç®—ã€‚
        è¿”å› ROI ç™¾åˆ†æ¯”ï¼Œè‹¥æ— æ³•è®¡ç®—è¿”å› Noneã€‚
        """
        sigs = await self.get_signatures(client, hunter_address, limit=self.audit_tx_limit)
        if not sigs:
            return None
        txs = await self.fetch_parsed_transactions(client, sigs)
        if not txs:
            return None
        parser = TransactionParser(hunter_address)
        calc = TokenAttributionCalculator()
        buy_sol, sell_sol, tokens_held = 0.0, 0.0, 0.0
        txs.sort(key=lambda x: x.get("timestamp", 0))
        for tx in txs:
            try:
                sol_change, token_changes, _ = parser.parse_transaction(tx)
                if token_address not in token_changes:
                    continue
                delta = token_changes[token_address]
                if abs(delta) < 1e-9:
                    continue
                buy_attrs, sell_attrs = calc.calculate_attribution(sol_change, token_changes)
                if token_address in buy_attrs:
                    buy_sol += buy_attrs[token_address]
                if token_address in sell_attrs:
                    sell_sol += sell_attrs[token_address]
                tokens_held += delta
            except Exception:
                continue
        if buy_sol < 0.01:
            return None
        total_value = sell_sol
        if tokens_held > 1e-9:
            price = await self._get_token_price_sol(client, token_address)
            if price is not None and price > 0:
                total_value += tokens_held * price
        roi = (total_value - buy_sol) / buy_sol * 100
        return roi

    async def verify_token_age_via_dexscreener(self, client, token_address):
        """è¿”å›: (is_valid_window, start_time, reason)"""
        url = f"https://api.dexscreener.com/latest/dex/tokens/{token_address}"
        try:
            resp = await client.get(url, timeout=5.0)
            if resp.status_code == 200:
                data = resp.json()
                pairs = data.get('pairs', [])
                if not pairs: return False, 0, "No Pairs"

                created_at_ms = min([p.get('pairCreatedAt', float('inf')) for p in pairs])
                if created_at_ms == float('inf'): return False, 0, "No Creation Time"

                created_at_sec = created_at_ms / 1000
                age = time.time() - created_at_sec

                if age < MIN_TOKEN_AGE_SEC:
                    return False, created_at_sec, f"Too Young ({age / 60:.1f}m)"
                if age > MAX_TOKEN_AGE_SEC:
                    return False, created_at_sec, f"Too Old ({age / 3600:.1f}h)"

                return True, created_at_sec, "OK"
            else:
                return False, 0, "API Error"
        except Exception:
            logger.exception("verify_token_age_via_dexscreener è¯·æ±‚å¼‚å¸¸")
            return False, 0, "Exception"

    async def search_alpha_hunters(self, token_address):
        if token_address in self.scanned_tokens: return []

        async with httpx.AsyncClient() as client:
            # 1. ä¸¥æ ¼çš„å¹´é¾„æ£€æŸ¥ (15m - 3h)
            is_valid, start_time, reason = await self.verify_token_age_via_dexscreener(client, token_address)
            if not is_valid:
                logger.info(f"â­ï¸ è·³è¿‡ä»£å¸ {token_address}: {reason}")
                return []

            logger.info(f"ğŸ” é”å®šé»„é‡‘çª—å£ä»£å¸ (å¹´é¾„ {time.time() - start_time:.0f}s)ï¼Œå¼€å§‹é«˜æ•ˆå›æº¯...")

            # 2. å›æº¯ç¿»é¡µ (å› ä¸ºåªæŒ–3å°æ—¶å†…çš„å¸ï¼Œç¿»é¡µå‹åŠ›å¾ˆå°)
            target_time_window = start_time + self.max_delay_sec
            current_before = None
            found_early_txs = []

            for page in range(MAX_BACKTRACK_PAGES):
                sigs = await self.get_signatures(client, token_address, limit=1000, before=current_before)
                if not sigs: break

                batch_oldest = sigs[-1].get('blockTime', 0)
                current_before = sigs[-1]['signature']

                if batch_oldest <= target_time_window:
                    logger.info(f"  ğŸ¯ ç¬¬{page + 1}é¡µè§¦è¾¾å¼€ç›˜åŒºé—´")
                    for s in sigs:
                        t = s.get('blockTime', 0)
                        if start_time <= t <= target_time_window:
                            found_early_txs.append(s)
                    break
                else:
                    logger.info(
                        f"  ğŸ“– ç¬¬{page + 1}é¡µ (æ—¶é—´: {time.strftime('%H:%M', time.gmtime(batch_oldest))}) -> ç»§ç»­å›æº¯")

            if not found_early_txs:
                logger.warning(f"âš ï¸ ç¿»äº†{MAX_BACKTRACK_PAGES}é¡µæœªè§¦åº•ï¼Œæ”¾å¼ƒ")
                self._save_scanned_token(token_address)
                return []

            # 3. è§£æäº¤æ˜“ (åŒå‰)
            found_early_txs.sort(key=lambda x: x.get('blockTime', 0))
            target_txs = found_early_txs[:100]
            txs = await self.fetch_parsed_transactions(client, target_txs)

            hunters_candidates = []
            seen_buyers = set()

            for tx in txs:
                block_time = tx.get('timestamp', 0)
                delay = block_time - start_time
                if delay < self.min_delay_sec: continue

                spender = None
                max_spend = 0
                for nt in tx.get('nativeTransfers', []):
                    amt = nt.get('amount', 0)
                    if amt > max_spend:
                        max_spend = amt
                        spender = nt.get('fromUserAccount')

                if not spender or spender in seen_buyers: continue
                spend_sol = max_spend / 1e9
                if SM_MIN_BUY_SOL <= spend_sol <= SM_MAX_BUY_SOL:
                    seen_buyers.add(spender)
                    hunters_candidates.append({"address": spender, "entry_delay": delay, "cost": spend_sol})

            logger.info(f"  [åˆç­›] 15ç§’åä¹°å…¥ä¸”é‡‘é¢åˆè§„: {len(hunters_candidates)} ä¸ª")

            # 3.5 è¿‡æ»¤ï¼šè¯¥ä»£å¸ä¸Šè‡³å°‘èµšå– 200%ï¼ˆå·²æ¸…ä»“æˆ–æœªæ¸…ä»“ï¼‰
            profit_filtered = []
            for candidate in hunters_candidates:
                roi = await self.get_hunter_profit_on_token(client, candidate["address"], token_address)
                if roi is not None and roi >= SM_MIN_TOKEN_PROFIT_PCT:
                    profit_filtered.append(candidate)
                    logger.debug(f"    é€šè¿‡ 200%% æ”¶ç›Šè¿‡æ»¤: {candidate['address'][:12]}.. ROI={roi:.0f}%%")
                await asyncio.sleep(0.3)
            hunters_candidates = profit_filtered
            logger.info(f"  [åˆç­›] åœ¨è¯¥ä»£å¸èµšå–â‰¥{SM_MIN_TOKEN_PROFIT_PCT:.0f}%: {len(hunters_candidates)} ä¸ª")

            # 4. æ·±åº¦å®¡è®¡ + è¯„åˆ†å…¥åº“
            verified_hunters = []
            for candidate in hunters_candidates:
                addr = candidate["address"]
                stats = await self.analyze_hunter_performance(client, addr, exclude_token=token_address)

                if stats:
                    score_hit_rate = stats["win_rate"]
                    delay = candidate["entry_delay"]
                    score_entry = max(0, 1 - (delay / self.max_delay_sec))
                    score_drawdown = 1 - abs(stats["worst_roi"] / 100)
                    score_drawdown = max(0, min(1, score_drawdown))

                    final_score = (score_hit_rate * 30) + (score_entry * 40) + (score_drawdown * 30)
                    final_score = round(final_score, 1)

                    is_qualified = False
                    if stats["total_profit"] > 0.1:
                        if stats["win_rate"] >= SM_MIN_WIN_RATE:
                            is_qualified = True
                        elif stats["total_profit"] >= SM_MIN_TOTAL_PROFIT:
                            is_qualified = True

                    if is_qualified:
                        candidate.update({
                            "score": final_score,
                            "win_rate": f"{stats['win_rate']:.1%}",
                            "worst_roi": f"{stats['worst_roi']:.1f}%",
                            "total_profit": f"{stats['total_profit']:.2f} SOL",
                            "scores_detail": f"H:{score_hit_rate:.2f}/E:{score_entry:.2f}/D:{score_drawdown:.2f}"
                        })
                        verified_hunters.append(candidate)
                        logger.info(
                            f"    âœ… é”å®šçŒæ‰‹ {addr}.. | åˆ©æ¶¦: {candidate['total_profit']} | è¯„åˆ†: {final_score}")
                await asyncio.sleep(0.5)

            self._save_scanned_token(token_address)
            return verified_hunters

    async def run_pipeline(self, dex_scanner_instance):
        logger.info("å¯åŠ¨ Alpha çŒæ‰‹æŒ–æ˜ (V7 çƒ­é—¨å¸ç‰ˆ: 24hæ¶¨å¹…>1000% | ä»£å¸â‰¤12h | åˆç­›15såä¹°å…¥ä¸”â‰¥200%æ”¶ç›Š)")
        hot_tokens = await dex_scanner_instance.scan()
        all_hunters = []
        if hot_tokens:
            for token in hot_tokens:
                addr = token.get('address')
                sym = token.get('symbol')
                if addr in self.scanned_tokens:
                    logger.info("â­ï¸ è·³è¿‡å·²æ‰«æä»£å¸: %s (%s)", sym, addr[:16] + "..")
                    continue
                logger.info(f"=== æ­£åœ¨æŒ–æ˜: {sym} ===")
                try:
                    hunters = await self.search_alpha_hunters(addr)
                    if hunters: all_hunters.extend(hunters)
                except Exception:
                    logger.exception("âŒ æŒ–æ˜ä»£å¸ %s å‡ºé”™", sym)
                await asyncio.sleep(1)
        all_hunters.sort(key=lambda x: x.get('score', 0), reverse=True)
        # åªä¿ç•™ 60 åˆ†åŠä»¥ä¸ŠçŒæ‰‹ï¼Œä¸çŒæ‰‹æ± å…¥åº“è§„åˆ™ä¸€è‡´
        return [h for h in all_hunters if h.get('score', 0) >= SM_MIN_HUNTER_SCORE]


if __name__ == "__main__":
    from services.dexscreener.dex_scanner import DexScanner


    async def main():
        searcher = SmartMoneySearcher()
        mock_scanner = DexScanner()
        results = await searcher.run_pipeline(mock_scanner)
        logger.info("====== æœ€ç»ˆæŒ–æ˜ç»“æœ (%s) ======", len(results))
        for res in results:
            logger.info("%s", res)


    asyncio.run(main())
